{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <div align=\"center\"><font color='green'> COSC 2673/2793 | Machine Learning  </font></div>\n",
    "## <div align=\"center\"> <font color='green'> **Example: Week08 Lecture QandA**</font></div>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Demo\n",
    "\n",
    "**Disclaimer: To simplify the example this code assumes the following without any investigations**\n",
    "\n",
    "> A polynormial classifier with degree 3 is assumed to be appropriate.\n",
    "\n",
    "> Hold out test set is used instead of cros-validation even though this might not be a good stratergy. \n",
    "\n",
    "> The objective is to demostrate how the techniques are used and not to come up with the best model.\n",
    "\n",
    "\n",
    "First lets load the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now load the dataset.\n",
    "> Dataset 1 is a modified version of the `PIMA Indians diabetes dataset` (Missing values resolved). The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiaPedigreeFunction', 'Age', 'Class']\n",
    "att_names = names[:-1]\n",
    "dataframe = pd.read_csv(url, names=names)\n",
    "dataframe.head(5)\n",
    "s_features = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set up the data into attributes and target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataframe['Class']\n",
    "X = dataframe.drop(['Class'], axis = 1)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first hold out some data for model evaluation. 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TrainX, TestX, TrainY, TestY = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets write a function to do model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "def get_trandformed_features(TrainX, TestX):\n",
    "    poly = PolynomialFeatures(3).fit(TrainX)\n",
    "    TrainX_poly = poly.transform(TrainX)\n",
    "    TestX_poly = poly.transform(TestX)\n",
    "    \n",
    "    scaler = preprocessing.MinMaxScaler().fit(TrainX_poly)\n",
    "\n",
    "    TrainX_poly = scaler.transform(TrainX_poly)\n",
    "    TestX_poly = scaler.transform(TestX_poly)\n",
    "    \n",
    "    return TrainX_poly, TestX_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def fit_model_predict_test(TrainX, TrainY, TestX):\n",
    "    logReg = LogisticRegression(C=100000, max_iter=100, solver='liblinear', class_weight='balanced', random_state=0)\n",
    "    \n",
    "    TrainX_poly, TestX_poly = get_trandformed_features(TrainX, TestX)\n",
    "    \n",
    "    logReg.fit(TrainX_poly, TrainY)\n",
    "    pred = logReg.predict(TestX_poly)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train a simple logistic regression model that use all the features. No regularaization (C = high value). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "pred = fit_model_predict_test(TrainX, TrainY, TestX)\n",
    "\n",
    "print(\"Test results for logistic regression with no feature selection\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred, average='macro'))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter methods - Example\n",
    "Lets first try a filter method in sk-learn first. for this we are plannig to use Mutual information mesure to establisth the \"best\" features. The number of features to pick is set to 5. \n",
    "\n",
    "Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "\n",
    "\n",
    "featureSelector = SelectKBest(score_func=mutual_info_classif, k=5).fit(TrainX, TrainY)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "scores = featureSelector.scores_\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.barh(att_names, scores, )\n",
    "\n",
    "# get the selected feature vectors\n",
    "TrainX_new = featureSelector.transform(TrainX)\n",
    "TestX_new = featureSelector.transform(TestX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now see how logistic regression works on selected features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(C=10000, max_iter=100, solver='liblinear', class_weight='balanced', random_state=0)\n",
    "\n",
    "pred = fit_model_predict_test(TrainX_new, TrainY, TestX_new)\n",
    "\n",
    "print(\"Test results for logistic regression with filtered feature selection\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred, average='macro'))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How will performance chage with the hyper-parameter k. Would you use cross valiadation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_all = np.arange(1,s_features+1)\n",
    "f1_hold = []\n",
    "acc_hold = []\n",
    "for k in k_all:\n",
    "    featureSelector = SelectKBest(score_func=f_classif, k=k).fit(TrainX, TrainY)\n",
    "    TrainX_new = featureSelector.transform(TrainX)\n",
    "    TestX_new = featureSelector.transform(TestX)\n",
    "    \n",
    "    # Should consider CV\n",
    "    pred = fit_model_predict_test(TrainX_new, TrainY, TestX_new)\n",
    "    \n",
    "    f1_hold.append(f1_score(TestY, pred, average='macro'))\n",
    "    acc_hold.append(accuracy_score (TestY, pred))\n",
    "\n",
    "plt.plot(k_all, f1_hold)\n",
    "plt.plot(k_all, acc_hold)\n",
    "plt.legend(['F1-score','Accuracy'])\n",
    "plt.xlabel('Number of features selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper methods - Example\n",
    "Next lets implement `Recursive Feature Elimination` which is a type of wrapper feature selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "TrainX_poly, TestX_poly = get_trandformed_features(TrainX, TestX)\n",
    "\n",
    "model = LogisticRegression(C=100000, max_iter=100, solver='liblinear', class_weight='balanced', random_state=0)\n",
    "\n",
    "rfe = RFE(model, 20).fit(TrainX_poly, TrainY)\n",
    "print(\"Num Features: %s\" % (rfe.n_features_))\n",
    "sel_inx = np.ix_(rfe.support_)[0].tolist()\n",
    "# print(\"Selected Features: %s\" % [att_names[i] for i in sel_inx])\n",
    "\n",
    "# get the selected feature vectors\n",
    "TrainX_new = rfe.transform(TrainX_poly)\n",
    "TestX_new = rfe.transform(TestX_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now see how logistic regression works on selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(C=100000, max_iter=100, solver='liblinear', class_weight='balanced', random_state=0)\n",
    "logReg.fit(TrainX_new, TrainY)\n",
    "pred = logReg.predict(TestX_new)\n",
    "\n",
    "print(\"Test results for logistic regression with Recursive Feature Elimination\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred, average='macro'))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded methods - Example\n",
    "Weel lets use l1 penalization. This is the Lasso penalty. Should use cross validation to set C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX_poly, TestX_poly = get_trandformed_features(TrainX, TestX)\n",
    "\n",
    "logReg = LogisticRegression(C=1, max_iter=100, solver='liblinear', class_weight='balanced', random_state=0)\n",
    "logReg.fit(TrainX_poly, TrainY)\n",
    "pred = logReg.predict(TestX_poly)\n",
    "\n",
    "\n",
    "print(\"Test results for logistic regression with l1 penalty\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred, average='macro'))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,8))\n",
    "# coef = pd.Series(np.squeeze(logReg.coef_), index = att_names)\n",
    "# imp_coef = coef.sort_values()\n",
    "# imp_coef.plot(kind = \"barh\")\n",
    "# plt.title(\"Feature importance using Lasso Linear Model\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree based feature selection - Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "tree_clf = ExtraTreesClassifier(n_estimators=100).fit(TrainX, TrainY)\n",
    "scores = tree_clf.feature_importances_  \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.barh(att_names, scores)\n",
    "\n",
    "model = SelectFromModel(tree_clf, prefit=True)\n",
    "TrainX_new = model.transform(TrainX)\n",
    "TestX_new = model.transform(TestX)\n",
    "print(\"Num Features: %s\" % (TrainX_new.shape[1]))\n",
    "\n",
    "tree_clf = ExtraTreesClassifier(n_estimators=100).fit(TrainX_new, TrainY)\n",
    "pred = tree_clf.predict(TestX_new)\n",
    "\n",
    "print(\"Test results for Random forest with tree feature selection\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred, average='macro'))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature construction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "TrainX_poly, TestX_poly = get_trandformed_features(TrainX, TestX)\n",
    "\n",
    "\n",
    "components = 10\n",
    "pca = PCA(n_components=components).fit(TrainX_poly)\n",
    "TrainX_new = pca.transform(TrainX_poly)\n",
    "TestX_new = pca.transform(TestX_poly)\n",
    "\n",
    "logReg = LogisticRegression(C=10000, max_iter=100, solver='liblinear', class_weight='balanced')\n",
    "logReg.fit(TrainX_new, TrainY)\n",
    "pred = logReg.predict(TestX_new)\n",
    "\n",
    "print(\"Test results for logistic regression with PCA feature construction\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred, average='macro'))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "plt.bar(np.arange(1,components+1), pca.explained_variance_ratio_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
